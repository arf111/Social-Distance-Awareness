{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QHnVupBBn9eR"
   },
   "source": [
    "# Detectron2 Beginner's Tutorial\n",
    "\n",
    "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
    "\n",
    "Welcome to detectron2! This is the official colab tutorial of detectron2. Here, we will go through some basics usage of detectron2, including the following:\n",
    "* Run inference on images or videos, with an existing detectron2 model\n",
    "* Train a detectron2 model on a new dataset\n",
    "\n",
    "You can make a copy of this tutorial or use \"File -> Open in playground mode\" to play with it yourself.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vM54r6jlKTII"
   },
   "source": [
    "# Install detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 766
    },
    "colab_type": "code",
    "id": "9_FzH13EjseR",
    "outputId": "16740954-ef34-4f36-bf1f-6940a73003c8"
   },
   "outputs": [],
   "source": [
    "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
    "!pip3 install --upgrade cython pyyaml==5.1\n",
    "!pip3 install --upgrade 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "import torch, torchvision\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "!gcc --version\n",
    "# opencv is pre-installed on colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 975
    },
    "colab_type": "code",
    "id": "b-i4hmGYk1dL",
    "outputId": "c30d97c7-5cba-419b-ba75-325920a8daf8"
   },
   "outputs": [],
   "source": [
    "# install detectron2:\n",
    "!pip3 install --upgrade 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZyAvNCJMmvFF"
   },
   "outputs": [],
   "source": [
    "# You may need to restart your runtime prior to this, to let your installation take effect\n",
    "# Some basic setup:\n",
    "# Setup detectron2 logger\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vk4gID50K03a"
   },
   "source": [
    "# Run a pre-trained detectron2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JgKyUL4pngvE"
   },
   "source": [
    "We first download a random image from the COCO dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HUjkwRsOn1O0",
    "outputId": "db54c08d-eb51-446e-c769-a3ccdcb2ab44"
   },
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model\n",
    "# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_101_FPN_3x.yaml\")\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "colab_type": "code",
    "id": "dq9GY37ml1kr",
    "outputId": "db2f51cd-715f-48b9-c186-86a12fd1eb1d"
   },
   "outputs": [],
   "source": [
    "# !wget http://images.cocodataset.org/val2017/000000439715.jpg -O input.jpg\n",
    "im = cv2.imread(\"./cov.jpg\")\n",
    "cv2_imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uM1thbN-ntjI"
   },
   "source": [
    "Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7d3KxiHO_0gb"
   },
   "outputs": [],
   "source": [
    "# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n",
    "# person_outputs = outputs[\"instances\"].pred_classes[0]\n",
    "outputs = predictor(im)\n",
    "person_instances = outputs[\"instances\"][outputs[\"instances\"].pred_classes[:] == 0] # get person predictions only\n",
    "boxes, pred_cls = person_instances.pred_boxes, person_instances.pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "ahvR6OnZ242W",
    "outputId": "d3eda58b-7bba-4688-a6c4-d054343c6216"
   },
   "outputs": [],
   "source": [
    "print(boxes)\n",
    "it = next(iter(boxes[2]))\n",
    "print(it[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "XBt0Dp9m4bD-",
    "outputId": "f73b2e20-4eb7-46ed-ad95-608cb8cab3c1"
   },
   "outputs": [],
   "source": [
    "# def draw_line():\n",
    "minm_dist = 0\n",
    "ratio = 0.4\n",
    "\n",
    "for i in person_instances.pred_boxes:\n",
    "  minm_dist = max(minm_dist,int(i[3] - i[1]))\n",
    "\n",
    "minm_dist = int(minm_dist * ratio)\n",
    "print(minm_dist)\n",
    "mid_points = person_instances.pred_boxes.get_centers()\n",
    "print(mid_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "8IRGo8d0qkgR",
    "outputId": "796060d7-cce8-4f3f-d940-e9e9ac68067d"
   },
   "outputs": [],
   "source": [
    "# We can use `Visualizer` to draw the predictions on the image.\n",
    "color = (1, 0, 0) \n",
    "\n",
    "close = 0\n",
    "\n",
    "vis = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "\n",
    "v = vis.draw_instance_predictions(person_instances.to(\"cpu\"))\n",
    "\n",
    "for i in range(len(mid_points)):\n",
    "  circle_coord = (int(mid_points[i,0]), int(mid_points[i,1]))\n",
    "  v = vis.draw_circle(circle_coord,color=(0,1,0))\n",
    "\n",
    "for i in range(len(mid_points)):\n",
    "  for j in range(i+1, len(mid_points)):\n",
    "    \n",
    "    euclid_dist = math.sqrt((mid_points[i,0] - mid_points[j,0])**2 + (mid_points[i,1] - mid_points[j,1])**2)\n",
    "    \n",
    "    if euclid_dist <= minm_dist:  \n",
    "      close += 1      \n",
    "      x_data = [int(mid_points[i,0].item()), int(mid_points[j,0].item())]\n",
    "      y_data = [int(mid_points[i,1].item()), int(mid_points[j,1].item())]\n",
    "      v = vis.draw_line(x_data,y_data, color)\n",
    "\n",
    "cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8BJWpwQGwWGX"
   },
   "source": [
    "# Inference Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1_ueveSxIcU"
   },
   "outputs": [],
   "source": [
    "def object_detection_api(pred, frame, rect_th=3, text_size=0.5, text_th=2, minm_dist = 0):\n",
    "\n",
    "    person_instances = pred\n",
    "\n",
    "    # boxes = person_instances.pred_boxes # Get predictions\n",
    "    \n",
    "    # if boxes:\n",
    "    #     for box in boxes:\n",
    "            \n",
    "    #         (x1,y1) = (box[0],box[1])\n",
    "    #         (x2,y2) = (box[2],box[3])\n",
    "\n",
    "    #         cv2.rectangle(frame, (x1,y1), (x2,y2), (0, 0, 255), rect_th) # Draw Rectangle with the coordinates\n",
    "    #         cv2.putText(frame, \"person\", (x1,y1),  cv2.FONT_HERSHEY_SIMPLEX, text_size, (0,255,0),thickness=text_th) # Write the prediction class\n",
    "    #     return frame\n",
    "    # else:\n",
    "    #     return frame\n",
    "    \n",
    "    mid_points = person_instances.pred_boxes.get_centers() # get middle point of boxes\n",
    "\n",
    "    vis = Visualizer(frame[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.0)\n",
    "\n",
    "    v = vis.draw_instance_predictions(person_instances.to(\"cpu\")) # draw the rectangle boxes\n",
    "        \n",
    "    # draw the circle mid point\n",
    "    for i in range(len(mid_points)):\n",
    "        circle_coord = (int(mid_points[i,0]), int(mid_points[i,1]))\n",
    "        v = vis.draw_circle(circle_coord, color=circle_col)\n",
    "    \n",
    "    # draw the lines that disobey social distance\n",
    "    for i in range(len(mid_points)):\n",
    "        for j in range(i+1, len(mid_points)):\n",
    "        \n",
    "            euclid_dist = math.sqrt((mid_points[i,0] - mid_points[j,0])**2 + (mid_points[i,1] - mid_points[j,1])**2)\n",
    "\n",
    "            if euclid_dist < minm_dist:  \n",
    "                x_data = [int(mid_points[i,0].item()), int(mid_points[j,0].item())]\n",
    "                y_data = [int(mid_points[i,1].item()), int(mid_points[j,1].item())]\n",
    "                v = vis.draw_line(x_data,y_data, line_col)\n",
    "\n",
    "    return v.get_image()[:, :, ::-1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "id": "oHhDgsRlwZdt",
    "outputId": "84106bf4-46fb-46cf-c6ec-a5ad3943b80a"
   },
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('inp3.mp4')\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('outputinpvid2.mp4',fourcc, 20.0,  (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# Set parameters\n",
    "ratio = 0.5\n",
    "\n",
    "line_col = (1, 0, 0) \n",
    "circle_col = (0,1,0)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        outputs = predictor(frame)\n",
    "        person_instances = outputs[\"instances\"][outputs[\"instances\"].pred_classes[:] == 0]  \n",
    "        \n",
    "        minm_dist = 0\n",
    "        \n",
    "        for i in person_instances.pred_boxes:\n",
    "            minm_dist = max(minm_dist,int(i[3] - i[1])) \n",
    "            minm_dist = int(minm_dist * ratio)\n",
    "                \n",
    "        frame = object_detection_api(person_instances, frame, minm_dist = minm_dist)\n",
    "        \n",
    "        out.write(frame)\n",
    "        \n",
    "        cv2.imshow('frame',frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Detectron2_Tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
